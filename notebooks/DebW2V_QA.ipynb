{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "637702c8-cbda-40c0-8bef-9179c902a02d",
   "metadata": {},
   "source": [
    "# モデルを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0bf4191-bb3a-426a-b66d-823954cfe63e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "69285b16-357f-4f83-936d-cd74996ab26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 30])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = torch.randn(3, 5, 30)\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a03310c-dbca-4a65-bb84-31aa22a75e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 20])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = nn.LSTM(30, 10, num_layers=3, dropout=0.3, bidirectional=True, batch_first=True)\n",
    "tmp, _ = lstm(tmp)\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d08e7416-5a95-4500-a572-4c250c20e1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 1])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln = nn.Linear(20, 1)\n",
    "tmp = ln(tmp)\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2d230632-5b3c-480e-9785-82106fb0dcfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2226],\n",
       "         [-0.2422],\n",
       "         [-0.2399],\n",
       "         [-0.2599],\n",
       "         [-0.2430]],\n",
       "\n",
       "        [[-0.2154],\n",
       "         [-0.2285],\n",
       "         [-0.2436],\n",
       "         [-0.2564],\n",
       "         [-0.2567]],\n",
       "\n",
       "        [[-0.2085],\n",
       "         [-0.2232],\n",
       "         [-0.2387],\n",
       "         [-0.2456],\n",
       "         [-0.2527]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4d1eb27a-3ae3-4219-9d1a-dcc8314c46b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = F.softmax(tmp, dim=1)\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fefd73e1-7dc4-4d04-928e-dbd96193e785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2038],\n",
       "         [0.1999],\n",
       "         [0.2003],\n",
       "         [0.1963],\n",
       "         [0.1997]],\n",
       "\n",
       "        [[0.2050],\n",
       "         [0.2023],\n",
       "         [0.1993],\n",
       "         [0.1967],\n",
       "         [0.1967]],\n",
       "\n",
       "        [[0.2051],\n",
       "         [0.2021],\n",
       "         [0.1990],\n",
       "         [0.1976],\n",
       "         [0.1962]]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b4bb695e-435c-4a1d-b7c7-aa1e2e3253ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aae8b517-086f-474f-bdf8-89b830d972e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 10, 5])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.X = torch.randn(15, 10, 5)\n",
    "        self.y = torch.randn(10)\n",
    "        self.num_data = 10\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_data\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x = self.X[i]\n",
    "        y = self.y[i]\n",
    "        return x, y\n",
    "dataset = MyDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=3)\n",
    "for data in dataloader:\n",
    "    print(data[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "51f498ca-5e89-4346-ab10-b336a0c4bef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 10,  20,  30],\n",
       "        [400, 500, 600]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = torch.tensor([[1,2,3],[4,5,6]])\n",
    "b = torch.tensor([[10],[100]])\n",
    "p*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ca00b43b-b480-43f6-91ec-ca58e5bf8d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3270],\n",
       "        [ 1.1937],\n",
       "        [ 1.2751],\n",
       "        [ 2.1794],\n",
       "        [-0.5897]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biln = nn.Bilinear(10, 10, 1)\n",
    "a = torch.randn(5, 10)\n",
    "b = torch.randn(5, 10)\n",
    "biln(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fefec43a-b860-4da3-9f4d-dc0cda021d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = torch.randn(3,3)\n",
    "tmp.sum(dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "141a46ed-49df-4bce-a822-cbe56e174e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.8941,  2.6537])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(2,5)\n",
    "b = torch.randn(5)\n",
    "a@b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3cfe2795-d6ee-402c-9565-3c9421d2413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DocReader(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layer, dropout):\n",
    "        super(DocReader, self).__init__()\n",
    "        self.P_Enc = nn.LSTM(\n",
    "            input_dim, hidden_dim, num_layers=num_layer,\n",
    "            dropout=dropout, bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.Q_Enc = nn.LSTM(\n",
    "            input_dim, hidden_dim, num_layers=num_layer,\n",
    "            dropout=dropout, bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.Q_AccumWeight = nn.Linear(hidden_dim*2, 1, bias=False)\n",
    "        self.Start_Pred = nn.Linear(hidden_dim*2, hidden_dim*2, bias=False)\n",
    "        self.End_Pred = nn.Linear(hidden_dim*2, hidden_dim*2, bias=False)\n",
    "\n",
    "    def forward(self, p, q):\n",
    "        p, _ = self.P_Enc(p)\n",
    "        q, _ = self.Q_Enc(q)\n",
    "        b = F.softmax(self.Q_AccumWeight(q), dim=1)\n",
    "        q = (q*b).sum(dim=1)\n",
    "        start_proba = F.softmax(torch.einsum('bnm,bm->bn', self.Start_Pred(p), q), dim=1)\n",
    "        end_proba = F.softmax(torch.einsum('bnm,bm->bn', self.End_Pred(p), q), dim=1)\n",
    "        return start_proba, end_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ddca0da0-e268-45f5-9169-79d0f060dc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DocReader(300, 128, 3, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e381c78e-be57-449e-8368-d876607ecfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.P = torch.randn(15, 10, 300)\n",
    "        self.Q = torch.randn(15, 5, 300)\n",
    "        self.num_data = 15\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_data\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        p = self.P[i]\n",
    "        q = self.Q[i]\n",
    "        return p, q\n",
    "dataset = MyDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1e895d58-356b-465e-9013-a574528a5ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5, 1])\n",
      "tensor([[0.5970],\n",
      "        [0.6031],\n",
      "        [0.6011],\n",
      "        [0.6004],\n",
      "        [0.5984]], grad_fn=<SumBackward1>)\n",
      "tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<SumBackward1>)\n",
      "tensor([[0.1992, 0.2006, 0.2002, 0.2008, 0.1992],\n",
      "        [0.2000, 0.2008, 0.2005, 0.1996, 0.1992],\n",
      "        [0.1978, 0.2017, 0.2004, 0.2001, 0.2000]], grad_fn=<SumBackward1>)\n",
      "\n",
      "\n",
      "torch.Size([3, 10])\n",
      "tensor([0.3015, 0.3007, 0.3003, 0.3015, 0.3001, 0.2997, 0.3000, 0.3002, 0.2982,\n",
      "        0.2978], grad_fn=<SumBackward1>)\n",
      "tensor([1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "for p, q in dataloader:\n",
    "    a,b = model(p, q)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "17d3da24-2b02-487e-8de3-daa24605bf60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 7, 9]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = torch.tensor([[1,2,3],[4,5,6]])\n",
    "tmp.sum(dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "79713102-206d-4f10-bd79-7f64d74fa1b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat2 must be a matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-c1692885bfd1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: mat2 must be a matrix"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2,3)\n",
    "b = torch.randn(3)\n",
    "torch.mm(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccbdd2b-0c82-4c06-9e71-c523e0761559",
   "metadata": {},
   "source": [
    "# データの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afdd3f08-1a9e-4fda-9971-4e93e2fc3470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from nltk.tokenize import word_tokenize\n",
    "import gensim\n",
    "import json\n",
    "torch.manual_seed(0)\n",
    "w2v_dim = 300\n",
    "w2v_undebiased = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)\n",
    "with open('data/squad1.1/train-v1.1.json', encoding='utf-8') as f:\n",
    "    train_dict = json.load(f)\n",
    "with open('data/squad1.1/dev-v1.1.json', encoding='utf-8') as f:\n",
    "    test_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ef3c22ab-83ad-4773-904c-4dda21c6046c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words_context = 0\n",
    "max_words_question = 0\n",
    "train_idxs = []\n",
    "for i, title in enumerate(train_dict['data']):\n",
    "    for j, paragraph in enumerate(title['paragraphs']):\n",
    "        num_words_context = len(word_tokenize(paragraph['context'].lower()))\n",
    "        if num_words_context > max_words_context:\n",
    "            max_words_context = num_words_context\n",
    "        for k, qa in enumerate(paragraph['qas']):\n",
    "            train_idxs.append(str(i)+'-'+str(j)+'-'+str(k))\n",
    "            num_words_question = len(word_tokenize(qa['question'].lower()))\n",
    "            if num_words_question > max_words_question:\n",
    "                max_words_question = num_words_question\n",
    "test_idxs = []\n",
    "for i, title in enumerate(test_dict['data']):\n",
    "    for j, paragraph in enumerate(title['paragraphs']):\n",
    "        num_words_context = len(word_tokenize(paragraph['context'].lower()))\n",
    "        if num_words_context > max_words_context:\n",
    "            max_words_context = num_words_context\n",
    "        for k, qa in enumerate(paragraph['qas']):\n",
    "            test_idxs.append(str(i)+'-'+str(j)+'-'+str(k))\n",
    "            num_words_question = len(word_tokenize(qa['question'].lower()))\n",
    "            if num_words_question > max_words_question:\n",
    "                max_words_question = num_words_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "74825cfc-a669-40df-b42b-c3e8be733e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "print(max_words_context)\n",
    "print(max_words_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "37facfdb-cfeb-433b-85a1-a17610341645",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 data_dict, index_lst,\n",
    "                 max_words_context, max_words_question, w2v_dim,\n",
    "                 w2v_model,\n",
    "                 isTrain):\n",
    "        self.data_dict = data_dict\n",
    "        self.index_lst = index_lst\n",
    "        self.num_data = len(index_lst)\n",
    "        self.max_words_context = max_words_context\n",
    "        self.max_words_question = max_words_question\n",
    "        self.w2v_dim = w2v_dim\n",
    "        self.w2v_model = w2v_model\n",
    "        self.isTrain = isTrain\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_data\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        idx = list(map(lambda x: int(x), self.index_lst[i].split('-')))\n",
    "        context = self.data_dict['data'][idx[0]]['paragraphs'][idx[1]]['context']\n",
    "        context = word_tokenize(context.lower())\n",
    "        context_emb = torch.zeros(self.max_words_context, self.w2v_dim)\n",
    "        for i, word in enumerate(context):\n",
    "            if word in self.w2v_model.key_to_index:\n",
    "                context_emb[i] += self.w2v_model[word]\n",
    "        question = self.data_dict['data'][idx[0]]['paragraphs'][idx[1]]['qas'][idx[2]]['question']\n",
    "        question = word_tokenize(question.lower())\n",
    "        question_emb = torch.zeros(self.max_words_question, self.w2v_dim)\n",
    "        for i, word in enumerate(question):\n",
    "            if word in self.w2v_model.key_to_index:\n",
    "                question_emb[i] += self.w2v_model[word]\n",
    "        answers = self.data_dict['data'][idx[0]]['paragraphs'][idx[1]]['qas'][idx[2]]['answers']\n",
    "        if self.isTrain:\n",
    "            answer = answers[0]\n",
    "            context = self.data_dict['data'][idx[0]]['paragraphs'][idx[1]]['context']\n",
    "            context = context[:answer['answer_start']] + ' start_point ' + context[answer['answer_start']:]\n",
    "            context = word_tokenize(context.lower())\n",
    "            start_idx = context.index('start_point')\n",
    "            end_idx = start_idx + len(word_tokenize(answer['text'])) - 1\n",
    "        else:\n",
    "            start_idx = []\n",
    "            end_idx = []\n",
    "            context = self.data_dict['data'][idx[0]]['paragraphs'][idx[1]]['context']\n",
    "            for answer in answers:\n",
    "                context_ = context[:answer['answer_start']] + ' start_point ' + context[answer['answer_start']:]\n",
    "                context_ = word_tokenize(context_.lower())\n",
    "                start_idx.append(context_.index('start_point'))\n",
    "                end_idx.append(start_idx[-1] + len(word_tokenize(answer['text'])) - 1)\n",
    "        return context_emb, question_emb, start_idx, end_idx\n",
    "\n",
    "train_set = MyDataset(train_dict, train_idxs, max_words_context, max_words_question, w2v_dim, w2v_undebiased, True)\n",
    "train_loader = DataLoader(train_set, batch_size=1, shuffle=True)\n",
    "test_set = MyDataset(test_dict, test_idxs, max_words_context, max_words_question, w2v_dim, w2v_undebiased, False)\n",
    "test_loader = DataLoader(test_set, batch_size=len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "199be58c-4f07-4476-ba4f-93d04bd0b85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Panthers finished the regular season with a 15–1 record, and quarterback Cam Newton was named the NFL Most Valuable Player (MVP). They defeated the Arizona Cardinals 49–15 in the NFC Championship Game and advanced to their second Super Bowl appearance since the franchise was founded in 1995. The Broncos finished the regular season with a 12–4 record, and denied the New England Patriots a chance to defend their title from Super Bowl XLIX by defeating them 20–18 in the AFC Championship Game. They joined the Patriots, Dallas Cowboys, and Pittsburgh Steelers as one of four teams that have made eight appearances in the Super Bowl.\n",
      "How many appearances have the Denver Broncos made in the Super Bowl?\n",
      "[{'answer_start': 467, 'text': '8'}, {'answer_start': 601, 'text': 'eight'}, {'answer_start': 601, 'text': 'eight'}]\n"
     ]
    }
   ],
   "source": [
    "print(test_dict['data'][0]['paragraphs'][1]['context'])\n",
    "print(test_dict['data'][0]['paragraphs'][1]['qas'][1]['question'])\n",
    "print(test_dict['data'][0]['paragraphs'][1]['qas'][1]['answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3fdbf73f-254c-409c-9490-ee9382883d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'is', 'a', 'pen', '.']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize('This  is a pen.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2c9456f9-72d9-49eb-883d-cfb5c1d6efa8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "each element in list of batch should be of equal size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-646a9707915d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mXc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mye\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mye\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0melem_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0melem_size\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: each element in list of batch should be of equal size"
     ]
    }
   ],
   "source": [
    "for Xc, Xq, ys, ye in test_loader:\n",
    "    print(Xc.shape)\n",
    "    print(Xq.shape)\n",
    "    print(ys)\n",
    "    print(ye)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37c0854f-33f2-45fa-af26-debf2ed44c47",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'version'])\n",
      "<class 'list'> 442\n",
      "dict_keys(['title', 'paragraphs'])\n",
      "<class 'list'> 55\n",
      "dict_keys(['context', 'qas'])\n",
      "<class 'list'> 5\n",
      "dict_keys(['answers', 'question', 'id'])\n",
      "{'answers': [{'answer_start': 515, 'text': 'Saint Bernadette Soubirous'}], 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'id': '5733be284776f41900661182'}\n",
      "Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n"
     ]
    }
   ],
   "source": [
    "print(train_dict.keys())\n",
    "print(type(train_dict['data']), len(train_dict['data']))\n",
    "print(train_dict['data'][0].keys())\n",
    "print(type(train_dict['data'][0]['paragraphs']), len(train_dict['data'][0]['paragraphs']))\n",
    "print(train_dict['data'][0]['paragraphs'][0].keys())\n",
    "print(type(train_dict['data'][0]['paragraphs'][0]['qas']), len(train_dict['data'][0]['paragraphs'][0]['qas']))\n",
    "print(train_dict['data'][0]['paragraphs'][0]['qas'][0].keys())\n",
    "print(train_dict['data'][0]['paragraphs'][0]['qas'][0])\n",
    "print(train_dict['data'][0]['paragraphs'][0]['context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "72c0faef-28f3-455f-9bd7-894c625967db",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'version'])\n",
      "<class 'list'> 48\n",
      "dict_keys(['title', 'paragraphs'])\n",
      "<class 'list'> 54\n",
      "dict_keys(['context', 'qas'])\n",
      "<class 'list'> 30\n",
      "dict_keys(['answers', 'question', 'id'])\n",
      "{'answers': [{'answer_start': 177, 'text': 'Denver Broncos'}, {'answer_start': 177, 'text': 'Denver Broncos'}, {'answer_start': 177, 'text': 'Denver Broncos'}], 'question': 'Which NFL team represented the AFC at Super Bowl 50?', 'id': '56be4db0acb8001400a502ec'}\n",
      "Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n"
     ]
    }
   ],
   "source": [
    "print(test_dict.keys())\n",
    "print(type(test_dict['data']), len(test_dict['data']))\n",
    "print(test_dict['data'][0].keys())\n",
    "print(type(test_dict['data'][0]['paragraphs']), len(test_dict['data'][0]['paragraphs']))\n",
    "print(test_dict['data'][0]['paragraphs'][0].keys())\n",
    "print(type(test_dict['data'][0]['paragraphs'][0]['qas']), len(test_dict['data'][0]['paragraphs'][0]['qas']))\n",
    "print(test_dict['data'][0]['paragraphs'][0]['qas'][0].keys())\n",
    "print(test_dict['data'][0]['paragraphs'][0]['qas'][0])\n",
    "print(test_dict['data'][0]['paragraphs'][0]['context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a3372e8d-25a8-4b89-b0c9-356611f1bf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "87599\n",
      "10567\n",
      "10570\n"
     ]
    }
   ],
   "source": [
    "# テストデータだけ複数答えがある→CrossEntropyで学習しても大丈夫\n",
    "index_lst = []\n",
    "for i, title in enumerate(train_data['data']):\n",
    "    for j, paragraph in enumerate(title['paragraphs']):\n",
    "        for k, qa in enumerate(paragraph['qas']):\n",
    "            index_lst.append(str(i)+'-'+str(j)+'-'+str(k))\n",
    "count = 0\n",
    "for i in range(len(index_lst)):\n",
    "    idx = list(map(lambda x: int(x), index_lst[i].split('-')))\n",
    "    answers = train_data['data'][idx[0]]['paragraphs'][idx[1]]['qas'][idx[2]]['answers']\n",
    "    if len(answers) > 1:\n",
    "#        print(answers)\n",
    "        count += 1\n",
    "print(count)\n",
    "print(len(index_lst))\n",
    "index_lst = []\n",
    "for i, title in enumerate(test_data['data']):\n",
    "    for j, paragraph in enumerate(title['paragraphs']):\n",
    "        for k, qa in enumerate(paragraph['qas']):\n",
    "            index_lst.append(str(i)+'-'+str(j)+'-'+str(k))\n",
    "count = 0\n",
    "for i in range(len(index_lst)):\n",
    "    idx = list(map(lambda x: int(x), index_lst[i].split('-')))\n",
    "    answers = test_data['data'][idx[0]]['paragraphs'][idx[1]]['qas'][idx[2]]['answers']\n",
    "    if len(answers) > 1:\n",
    "#        print(answers)\n",
    "        count += 1\n",
    "print(count)\n",
    "print(len(index_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9617d4de-54f3-4d70-8b9a-c8b4f7e0d5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
      "Which NFL team represented the AFC at Super Bowl 50?\n",
      "[{'answer_start': 177, 'text': 'Denver Broncos'}, {'answer_start': 177, 'text': 'Denver Broncos'}, {'answer_start': 177, 'text': 'Denver Broncos'}]\n",
      "\n",
      "Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
      "Which NFL team represented the NFC at Super Bowl 50?\n",
      "[{'answer_start': 249, 'text': 'Carolina Panthers'}, {'answer_start': 249, 'text': 'Carolina Panthers'}, {'answer_start': 249, 'text': 'Carolina Panthers'}]\n",
      "\n",
      "Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
      "Where did Super Bowl 50 take place?\n",
      "[{'answer_start': 403, 'text': 'Santa Clara, California'}, {'answer_start': 355, 'text': \"Levi's Stadium\"}, {'answer_start': 355, 'text': \"Levi's Stadium in the San Francisco Bay Area at Santa Clara, California.\"}]\n",
      "\n",
      "Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
      "Which NFL team won Super Bowl 50?\n",
      "[{'answer_start': 177, 'text': 'Denver Broncos'}, {'answer_start': 177, 'text': 'Denver Broncos'}, {'answer_start': 177, 'text': 'Denver Broncos'}]\n",
      "\n",
      "Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
      "What color was used to emphasize the 50th anniversary of the Super Bowl?\n",
      "[{'answer_start': 488, 'text': 'gold'}, {'answer_start': 488, 'text': 'gold'}, {'answer_start': 521, 'text': 'gold'}]\n",
      "\n",
      "Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
      "What was the theme of Super Bowl 50?\n",
      "[{'answer_start': 487, 'text': '\"golden anniversary\"'}, {'answer_start': 521, 'text': 'gold-themed'}, {'answer_start': 487, 'text': '\"golden anniversary'}]\n",
      "\n",
      "Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
      "What day was the game played on?\n",
      "[{'answer_start': 334, 'text': 'February 7, 2016'}, {'answer_start': 334, 'text': 'February 7'}, {'answer_start': 334, 'text': 'February 7, 2016'}]\n",
      "\n",
      "Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
      "What is the AFC short for?\n",
      "[{'answer_start': 133, 'text': 'American Football Conference'}, {'answer_start': 133, 'text': 'American Football Conference'}, {'answer_start': 133, 'text': 'American Football Conference'}]\n",
      "\n",
      "Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
      "What was the theme of Super Bowl 50?\n",
      "[{'answer_start': 487, 'text': '\"golden anniversary\"'}, {'answer_start': 521, 'text': 'gold-themed'}, {'answer_start': 521, 'text': 'gold'}]\n",
      "\n",
      "Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
      "What does AFC stand for?\n",
      "[{'answer_start': 133, 'text': 'American Football Conference'}, {'answer_start': 133, 'text': 'American Football Conference'}, {'answer_start': 133, 'text': 'American Football Conference'}]\n",
      "\n",
      "Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
      "What day was the Super Bowl played on?\n",
      "[{'answer_start': 334, 'text': 'February 7, 2016'}, {'answer_start': 334, 'text': 'February 7'}, {'answer_start': 334, 'text': 'February 7, 2016'}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i, title in enumerate(test_dict['data']):\n",
    "    for j, paragraph in enumerate(title['paragraphs']):\n",
    "        for k, qa in enumerate(paragraph['qas']):\n",
    "            print(test_dict['data'][i]['paragraphs'][j]['context'])\n",
    "            print(test_dict['data'][i]['paragraphs'][j]['qas'][k]['question'])\n",
    "            print(test_dict['data'][i]['paragraphs'][j]['qas'][k]['answers'])\n",
    "            print()\n",
    "            count += 1\n",
    "            if count > 10:\n",
    "                break\n",
    "        if count > 10:\n",
    "            break\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716765b5-6949-4742-8e88-b575232af685",
   "metadata": {},
   "source": [
    "# 実験"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce1d9e11-4c19-4bfd-aca2-9ca0e6d39906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabriel\\anaconda3\\envs\\torch\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "import gensim\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "600f545f-bb97-4a25-87e2-de78ec6f8563",
   "metadata": {},
   "outputs": [],
   "source": [
    "isModeling = True\n",
    "\n",
    "# data loaderのため\n",
    "torch.manual_seed(0)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"device:\", device)\n",
    "\n",
    "w2v_undebiased = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)\n",
    "w2v_debiased = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300-hard-debiased.bin', binary=True)\n",
    "w2v_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4969671e-1440-431b-9cf9-3faf18634b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/squad1.1/train-v1.1.json', encoding='utf-8') as f:\n",
    "    data_dict = json.load(f)\n",
    "\n",
    "max_words_context = 0\n",
    "max_words_question = 0\n",
    "data_idxs = []\n",
    "for i, title in enumerate(data_dict['data']):\n",
    "    for j, paragraph in enumerate(title['paragraphs']):\n",
    "        num_words_context = len(word_tokenize(paragraph['context'].lower()))\n",
    "        if num_words_context > max_words_context:\n",
    "            max_words_context = num_words_context\n",
    "        for k, qa in enumerate(paragraph['qas']):\n",
    "            data_idxs.append(str(i)+'-'+str(j)+'-'+str(k))\n",
    "            num_words_question = len(word_tokenize(qa['question'].lower()))\n",
    "            if num_words_question > max_words_question:\n",
    "                max_words_question = num_words_question\n",
    "train_idxs, test_idxs = train_test_split(data_idxs, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d853806a-bf39-4727-a653-9a7e412f8b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70079\n",
      "17520\n",
      "239.99657534246575\n",
      "60.0\n"
     ]
    }
   ],
   "source": [
    "print(len(train_idxs))\n",
    "print(len(test_idxs))\n",
    "print(len(train_idxs) / 292)\n",
    "print(len(test_idxs) / 292)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "177508c4-5ace-41ad-9e22-ae34e7cfd79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 data_dict, index_lst,\n",
    "                 max_words_context, max_words_question, w2v_dim,\n",
    "                 w2v_model):\n",
    "        self.data_dict = data_dict\n",
    "        self.index_lst = index_lst\n",
    "        self.num_data = len(index_lst)\n",
    "        self.max_words_context = max_words_context\n",
    "        self.max_words_question = max_words_question\n",
    "        self.w2v_dim = w2v_dim\n",
    "        self.w2v_model = w2v_model\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_data\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        idx = list(map(lambda x: int(x), self.index_lst[i].split('-')))\n",
    "        context = self.data_dict['data'][idx[0]]['paragraphs'][idx[1]]['context']\n",
    "        context = word_tokenize(context.lower())\n",
    "        context_emb = torch.zeros(self.max_words_context, self.w2v_dim)\n",
    "        for i, word in enumerate(context):\n",
    "            if word in self.w2v_model.key_to_index:\n",
    "                context_emb[i] += self.w2v_model[word]\n",
    "        question = self.data_dict['data'][idx[0]]['paragraphs'][idx[1]]['qas'][idx[2]]['question']\n",
    "        question = word_tokenize(question.lower())\n",
    "        question_emb = torch.zeros(self.max_words_question, self.w2v_dim)\n",
    "        for i, word in enumerate(question):\n",
    "            if word in self.w2v_model.key_to_index:\n",
    "                question_emb[i] += self.w2v_model[word]\n",
    "        answer = self.data_dict['data'][idx[0]]['paragraphs'][idx[1]]['qas'][idx[2]]['answers'][0]\n",
    "        context = self.data_dict['data'][idx[0]]['paragraphs'][idx[1]]['context']\n",
    "        context = context[:answer['answer_start']] + ' _start_point_ ' + context[answer['answer_start']:]\n",
    "        context = word_tokenize(context.lower())\n",
    "        start_idx = context.index('_start_point_')\n",
    "        end_idx = start_idx + len(word_tokenize(answer['text'])) - 1\n",
    "        return context_emb, question_emb, start_idx, end_idx\n",
    "\n",
    "udb_train_set = MyDataset(data_dict, train_idxs, max_words_context, max_words_question, w2v_dim, w2v_undebiased)\n",
    "udb_test_set = MyDataset(data_dict, test_idxs, max_words_context, max_words_question, w2v_dim, w2v_undebiased)\n",
    "db_train_set = MyDataset(data_dict, train_idxs, max_words_context, max_words_question, w2v_dim, w2v_debiased)\n",
    "db_test_set = MyDataset(data_dict, test_idxs, max_words_context, max_words_question, w2v_dim, w2v_debiased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12924d39-b74e-44a2-b423-9de4500d809c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力：文書と質問(バッチ数x単語数x分散表現の次元)\n",
    "# 出力：文書の中で答えと予想される範囲の始まりと終わりの分布(バッチ数x単語数)\n",
    "class DocReader(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layer, dropout):\n",
    "        super(DocReader, self).__init__()\n",
    "        self.P_Enc = nn.LSTM(\n",
    "            input_dim, hidden_dim, num_layers=num_layer,\n",
    "            dropout=dropout, bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.Q_Enc = nn.LSTM(\n",
    "            input_dim, hidden_dim, num_layers=num_layer,\n",
    "            dropout=dropout, bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.Q_AccumWeight = nn.Linear(hidden_dim*2, 1, bias=False)\n",
    "        self.Start_Pred = nn.Linear(hidden_dim*2, hidden_dim*2, bias=False)\n",
    "        self.End_Pred = nn.Linear(hidden_dim*2, hidden_dim*2, bias=False)\n",
    "\n",
    "    def forward(self, p, q):\n",
    "        p, _ = self.P_Enc(p)\n",
    "        q, _ = self.Q_Enc(q)\n",
    "        b = F.softmax(self.Q_AccumWeight(q), dim=1)\n",
    "        q = (q*b).sum(dim=1)\n",
    "        pred_start = torch.einsum('bnm,bm->bn', self.Start_Pred(p), q)\n",
    "        pred_end = torch.einsum('bnm,bm->bn', self.End_Pred(p), q)\n",
    "        return pred_start, pred_end\n",
    "\n",
    "num_epoch = 10\n",
    "num_experiment = 100\n",
    "LSTM_hidden_dim = 128\n",
    "LSTM_num_layer = 3\n",
    "dropout_rate = 0.3\n",
    "lr = 0.1\n",
    "\n",
    "def eval_exact_match(pred_start, pred_end, y_start, y_end):\n",
    "    pred_start = pred_start.max(dim=1).indices\n",
    "    pred_end = pred_end.max(dim=1).indices\n",
    "    match = torch.logical_and(pred_start==y_start, pred_end==y_end)\n",
    "    return match.sum() / len(match)\n",
    "\n",
    "def eval_f1(pred_start, pred_end, y_start, y_end):\n",
    "    pred_start = pred_start.max(dim=1).indices\n",
    "    pred_end = pred_end.max(dim=1).indices\n",
    "    start_diff = pred_start - y_start\n",
    "    start_diff = torch.where(start_diff > 0, start_diff, 0)\n",
    "    end_diff = y_end - pred_end\n",
    "    end_diff = torch.where(end_diff > 0, end_diff, 0)\n",
    "    TP = (y_end - y_start + 1 - start_diff - end_diff).double()\n",
    "    TP = torch.where(TP > 0, TP, 1e-10) # TP=0だとf1がnanになる\n",
    "    recall = TP / (y_end - y_start + 1)\n",
    "    pred_diff = pred_end - pred_start\n",
    "    pred_diff = torch.where(pred_diff > 0, pred_diff, 0)\n",
    "    precision = TP / (pred_diff + 1)\n",
    "#     precision = TP / (pred_end - pred_start + 1)\n",
    "    f1 = 2*recall*precision / (recall + precision)\n",
    "#     if torch.any(torch.logical_or(f1.isnan(), f1.isinf())):\n",
    "#         print('recall:', recall)\n",
    "#         print('precision:', precision)\n",
    "    return f1.mean()\n",
    "\n",
    "def train(isModeling, train_loader, test_loader, representation):\n",
    "    if isModeling:\n",
    "        num_experiment = 1\n",
    "    else:\n",
    "        em_scores = []\n",
    "        f1_scores = []\n",
    "        preds = []\n",
    "    for experiment in range(num_experiment):\n",
    "        # modelの初期値のため\n",
    "        torch.manual_seed(experiment)\n",
    "        model = DocReader(w2v_dim, LSTM_hidden_dim, LSTM_num_layer, dropout_rate).to(device)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adamax(model.parameters(), lr=lr)\n",
    "\n",
    "        train_loss_log = []\n",
    "        eval_loss_log = []\n",
    "        eval_em_log = []\n",
    "        eval_f1_log = []\n",
    "        for epoch in range(num_epoch):\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            for X_context, X_question, y_start, y_end in train_loader:\n",
    "                X_context = X_context.to(device)\n",
    "                X_question = X_question.to(device)\n",
    "                y_start = y_start.to(device)\n",
    "                y_end = y_end.to(device)\n",
    "                pred_start, pred_end = model(X_context, X_question)\n",
    "                loss = loss_fn(pred_start, y_start) + loss_fn(pred_end, y_end)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss*len(y_start)\n",
    "            train_loss /= len(train_idxs)\n",
    "            train_loss_log.append(train_loss.cpu().item())\n",
    "\n",
    "            model.eval()\n",
    "            eval_loss = 0\n",
    "            em_total = 0\n",
    "            f1_total = 0\n",
    "            with torch.no_grad():\n",
    "                for X_context, X_question, y_start, y_end in test_loader:\n",
    "                    X_context = X_context.to(device)\n",
    "                    X_question = X_question.to(device)\n",
    "                    y_start = y_start.to(device)\n",
    "                    y_end = y_end.to(device)\n",
    "                    pred_start, pred_end = model(X_context, X_question)\n",
    "                    loss = loss_fn(pred_start, y_start) + loss_fn(pred_end, y_end)\n",
    "                    eval_loss += loss\n",
    "                    em = eval_exact_match(pred_start, pred_end, y_start, y_end)\n",
    "                    em_total += em\n",
    "                    f1 = eval_f1(pred_start, pred_end, y_start, y_end)\n",
    "                    f1_total += f1\n",
    "                eval_loss /= len(test_loader)\n",
    "                eval_loss_log.append(eval_loss.cpu().item())\n",
    "                em_total /= len(test_loader)\n",
    "                eval_em_log.append(em_total.cpu().item())\n",
    "                f1_total /= len(test_loader)\n",
    "                eval_f1_log.append(f1_total.cpu().item())\n",
    "            if isModeling:\n",
    "                print('Epoch{}'.format(epoch+1))\n",
    "                print('loss train:{:.4}, test:{:.4}'.format(train_loss, eval_loss))\n",
    "                print('score EM:{:.4}, F1:{:.4}'.format(em_total, f1_total))\n",
    "\n",
    "        if isModeling:\n",
    "            fig = plt.figure()\n",
    "            ax = fig.add_subplot(1, 1, 1)\n",
    "            ax.plot(range(1, 11), train_loss_log, label='train loss')\n",
    "            ax.plot(range(1, 11), eval_loss_log, label='eval loss')\n",
    "            fig.suptitle('loss log')\n",
    "            fig.legend()\n",
    "            fig.show()\n",
    "\n",
    "            fig = plt.figure()\n",
    "            ax = fig.add_subplot(1, 1, 1)\n",
    "            ax.plot(range(1, 11), eval_em_log, label='Exact Match')\n",
    "            ax.plot(range(1, 11), eval_f1_log, label='F1')\n",
    "            fig.suptitle('acc log')\n",
    "            fig.legend()\n",
    "            fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c811359d-eda2-4e4a-8fa0-671039e4fcee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1\n",
      "loss train:13.49, test:10.12\n",
      "score EM:0.0, F1:6.469e-11\n",
      "Epoch2\n",
      "loss train:9.632, test:9.051\n",
      "score EM:0.002397, F1:0.05234\n",
      "Epoch3\n",
      "loss train:8.834, test:8.354\n",
      "score EM:0.01438, F1:0.03983\n",
      "Epoch4\n",
      "loss train:8.499, test:8.288\n",
      "score EM:0.01558, F1:0.0491\n",
      "Epoch5\n",
      "loss train:8.434, test:8.126\n",
      "score EM:0.023, F1:0.05182\n",
      "Epoch6\n",
      "loss train:8.309, test:8.093\n",
      "score EM:0.02534, F1:0.05836\n",
      "Epoch7\n",
      "loss train:8.346, test:8.016\n",
      "score EM:0.02728, F1:0.05727\n",
      "Epoch8\n",
      "loss train:8.238, test:8.015\n",
      "score EM:0.03202, F1:0.06169\n",
      "Epoch9\n",
      "loss train:8.132, test:7.983\n",
      "score EM:0.0238, F1:0.06217\n",
      "Epoch10\n",
      "loss train:8.089, test:7.945\n",
      "score EM:0.02865, F1:0.06494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-6d008b339f78>:132: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'show' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-2295af3b157a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# db_train_loader = DataLoader(udb_train_set, batch_size=batch_size, shuffle=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# db_test_loader = DataLoader(udb_test_set, batch_size=batch_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mudb_train_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mudb_test_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'udb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-6d008b339f78>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(isModeling, train_loader, test_loader, representation)\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_f1_log\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'F1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'acc log'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'show' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 292\n",
    "udb_train_loader = DataLoader(udb_train_set, batch_size=batch_size, shuffle=True)\n",
    "udb_test_loader = DataLoader(udb_test_set, batch_size=batch_size)\n",
    "# db_train_loader = DataLoader(udb_train_set, batch_size=batch_size, shuffle=True)\n",
    "# db_test_loader = DataLoader(udb_test_set, batch_size=batch_size)\n",
    "train(True, udb_train_loader, udb_test_loader, 'udb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016aa2f1-fbfe-42d8-9795-a55d8d4207d7",
   "metadata": {},
   "source": [
    "# DataLoader改善"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d556061b-d2a1-4208-9ba0-c51037f07efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cce8cb29-2649-4df1-886c-4db94dc1fb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabriel\\anaconda3\\envs\\torch\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "preparing data\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "import gensim\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "isModeling = True\n",
    "num_experiment = 100\n",
    "num_epoch = 100\n",
    "LSTM_hidden_dim = 128\n",
    "LSTM_num_layer = 3\n",
    "dropout_rate = 0.3\n",
    "lr = 0.05\n",
    "batch_size = 292\n",
    "\n",
    "# data loaderのため\n",
    "torch.manual_seed(0)\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"device:\", device)\n",
    "\n",
    "if not os.path.isdir('.data'):\n",
    "    os.mkdir('.data')\n",
    "if not os.path.isdir('figs'):\n",
    "    os.mkdir('figs')\n",
    "\n",
    "print('preparing data')\n",
    "w2v_undebiased = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)\n",
    "w2v_debiased = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300-hard-debiased.bin', binary=True)\n",
    "w2v_dim = 300\n",
    "\n",
    "with open('data/squad1.1/train-v1.1.json', encoding='utf-8') as f:\n",
    "    data_dict = json.load(f)\n",
    "\n",
    "max_words_context = 0\n",
    "max_words_question = 0\n",
    "data_idxs = []\n",
    "for i, title in enumerate(data_dict['data']):\n",
    "    for j, paragraph in enumerate(title['paragraphs']):\n",
    "        num_words_context = len(word_tokenize(paragraph['context'].lower()))\n",
    "        if num_words_context > max_words_context:\n",
    "            max_words_context = num_words_context\n",
    "        for k, qa in enumerate(paragraph['qas']):\n",
    "            data_idxs.append(str(i)+'-'+str(j)+'-'+str(k))\n",
    "            num_words_question = len(word_tokenize(qa['question'].lower()))\n",
    "            if num_words_question > max_words_question:\n",
    "                max_words_question = num_words_question\n",
    "train_idxs, test_idxs = train_test_split(data_idxs, test_size=0.2, random_state=0)\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 data_dict, index_lst,\n",
    "                 max_words_context, max_words_question, w2v_dim,\n",
    "                 w2v_model):\n",
    "        self.data_dict = data_dict\n",
    "        self.index_lst = index_lst\n",
    "        self.num_data = len(index_lst)\n",
    "        self.max_words_context = max_words_context\n",
    "        self.max_words_question = max_words_question\n",
    "        self.w2v_dim = w2v_dim\n",
    "        self.w2v_model = w2v_model\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_data\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        idx = list(map(lambda x: int(x), self.index_lst[i].split('-')))\n",
    "        context = self.data_dict['data'][idx[0]]['paragraphs'][idx[1]]['context']\n",
    "        context = word_tokenize(context.lower())\n",
    "        context_emb = torch.zeros(self.max_words_context, self.w2v_dim)\n",
    "        for i, word in enumerate(context):\n",
    "            if word in self.w2v_model.key_to_index:\n",
    "                context_emb[i] += self.w2v_model[word]\n",
    "        question = self.data_dict['data'][idx[0]]['paragraphs'][idx[1]]['qas'][idx[2]]['question']\n",
    "        question = word_tokenize(question.lower())\n",
    "        question_emb = torch.zeros(self.max_words_question, self.w2v_dim)\n",
    "        for i, word in enumerate(question):\n",
    "            if word in self.w2v_model.key_to_index:\n",
    "                question_emb[i] += self.w2v_model[word]\n",
    "        answer = self.data_dict['data'][idx[0]]['paragraphs'][idx[1]]['qas'][idx[2]]['answers'][0]\n",
    "        context = self.data_dict['data'][idx[0]]['paragraphs'][idx[1]]['context']\n",
    "        context = context[:answer['answer_start']] + ' _start_point_ ' + context[answer['answer_start']:]\n",
    "        context = word_tokenize(context.lower())\n",
    "        start_idx = context.index('_start_point_')\n",
    "        end_idx = start_idx + len(word_tokenize(answer['text'])) - 1\n",
    "        return context_emb, question_emb, start_idx, end_idx\n",
    "\n",
    "# 入力：文書と質問(バッチ数x単語数x分散表現の次元)\n",
    "# 出力：文書の中で答えと予想される範囲の始まりと終わりの分布(バッチ数x単語数)\n",
    "class DocReader(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layer, dropout):\n",
    "        super(DocReader, self).__init__()\n",
    "        self.P_Enc = nn.LSTM(\n",
    "            input_dim, hidden_dim, num_layers=num_layer,\n",
    "            dropout=dropout, bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.Q_Enc = nn.LSTM(\n",
    "            input_dim, hidden_dim, num_layers=num_layer,\n",
    "            dropout=dropout, bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.Q_AccumWeight = nn.Linear(hidden_dim*2, 1, bias=False)\n",
    "        self.Start_Pred = nn.Linear(hidden_dim*2, hidden_dim*2, bias=False)\n",
    "        self.End_Pred = nn.Linear(hidden_dim*2, hidden_dim*2, bias=False)\n",
    "\n",
    "    def forward(self, p, q):\n",
    "        p, _ = self.P_Enc(p)\n",
    "        q, _ = self.Q_Enc(q)\n",
    "        b = F.softmax(self.Q_AccumWeight(q), dim=1)\n",
    "        q = (q*b).sum(dim=1)\n",
    "        pred_start = torch.einsum('bnm,bm->bn', self.Start_Pred(p), q)\n",
    "        pred_end = torch.einsum('bnm,bm->bn', self.End_Pred(p), q)\n",
    "        return pred_start, pred_end\n",
    "\n",
    "def eval_exact_match(pred_start, pred_end, y_start, y_end):\n",
    "    pred_start = pred_start.max(dim=1).indices\n",
    "    pred_end = pred_end.max(dim=1).indices\n",
    "    match = torch.logical_and(pred_start==y_start, pred_end==y_end)\n",
    "    return match.sum() / len(match)\n",
    "\n",
    "def eval_f1(pred_start, pred_end, y_start, y_end):\n",
    "    pred_start = pred_start.max(dim=1).indices\n",
    "    pred_end = pred_end.max(dim=1).indices\n",
    "    start_diff = pred_start - y_start\n",
    "    start_diff = torch.where(start_diff > 0, start_diff, 0)\n",
    "    end_diff = y_end - pred_end\n",
    "    end_diff = torch.where(end_diff > 0, end_diff, 0)\n",
    "    TP = (y_end - y_start + 1 - start_diff - end_diff).double()\n",
    "    TP = torch.where(TP > 0, TP, 1e-10) # TP=0だとf1がnanになる\n",
    "    recall = TP / (y_end - y_start + 1)\n",
    "    pred_diff = pred_end - pred_start\n",
    "    pred_diff = torch.where(pred_diff > 0, pred_diff, 0)\n",
    "    precision = TP / (pred_diff + 1)\n",
    "    f1 = 2*recall*precision / (recall + precision)\n",
    "    return f1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f777b1d-925a-4136-9010-0e74c1d7616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(isModeling, train_loader, test_loader, representation):\n",
    "    \n",
    "    time0 = time.time()\n",
    "    \n",
    "    print('{} model'.format(representation))\n",
    "    num_experiment = 1\n",
    "    for experiment in range(num_experiment):\n",
    "        model = DocReader(w2v_dim, LSTM_hidden_dim, LSTM_num_layer, dropout_rate).to(device)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adamax(model.parameters(), lr=lr)\n",
    "\n",
    "        time1 = time.time()\n",
    "        print('prepare:{:.2}'.format(time1 - time0))\n",
    "        print()\n",
    "\n",
    "        for epoch in range(num_epoch):\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            \n",
    "            time0 = time.time()\n",
    "            \n",
    "            for X_context, X_question, y_start, y_end in train_loader:\n",
    "                \n",
    "                time1 = time.time()\n",
    "                print('data loading:{:.2}'.format(time1 - time0))\n",
    "                \n",
    "                X_context = X_context.to(device)\n",
    "                X_question = X_question.to(device)\n",
    "                y_start = y_start.to(device)\n",
    "                y_end = y_end.to(device)\n",
    "                \n",
    "                time2 = time.time()\n",
    "                print('data moving:{:.2}'.format(time2 - time1))\n",
    "                \n",
    "                pred_start, pred_end = model(X_context, X_question)\n",
    "                \n",
    "                time3 = time.time()\n",
    "                print('predicting:{:.2}'.format(time3 - time2))\n",
    "                \n",
    "                loss = loss_fn(pred_start, y_start) + loss_fn(pred_end, y_end)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss*len(y_start)\n",
    "                \n",
    "                time4 = time.time()\n",
    "                print('backwarding:{:.2}'.format(time4 - time3))\n",
    "                print()\n",
    "                \n",
    "                time0 = time.time()\n",
    "\n",
    "            train_loss /= len(train_idxs)\n",
    "\n",
    "            model.eval()\n",
    "            eval_loss = 0\n",
    "            em_total = 0\n",
    "            f1_total = 0\n",
    "            with torch.no_grad():\n",
    "                \n",
    "                time0 = time.time()\n",
    "                \n",
    "                for X_context, X_question, y_start, y_end in test_loader:\n",
    "                    \n",
    "                    time1 = time.time()\n",
    "                    print('data loading:{:.2}'.format(time1 - time0))\n",
    "                    \n",
    "                    X_context = X_context.to(device)\n",
    "                    X_question = X_question.to(device)\n",
    "                    y_start = y_start.to(device)\n",
    "                    y_end = y_end.to(device)\n",
    "                    \n",
    "                    time2 = time.time()\n",
    "                    print('data moving:{:.2}'.format(time2 - time1))\n",
    "                    \n",
    "                    pred_start, pred_end = model(X_context, X_question)\n",
    "                    \n",
    "                    time3 = time.time()\n",
    "                    print('predicting:{:.2}'.format(time3 - time2))\n",
    "                    \n",
    "                    loss = loss_fn(pred_start, y_start) + loss_fn(pred_end, y_end)\n",
    "                    eval_loss += loss\n",
    "                    em = eval_exact_match(pred_start, pred_end, y_start, y_end)\n",
    "                    em_total += em\n",
    "                    f1 = eval_f1(pred_start, pred_end, y_start, y_end)\n",
    "                    f1_total += f1\n",
    "                    \n",
    "                    time4 = time.time()\n",
    "                    print('evaluating:{:.2}'.format(time4 - time3))\n",
    "                    print()\n",
    "                    \n",
    "                eval_loss /= len(test_loader)\n",
    "                em_total /= len(test_loader)\n",
    "                f1_total /= len(test_loader)\n",
    "    if isModeling:\n",
    "        return None\n",
    "    else:\n",
    "        return em_scores, f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cba6dd-3d2b-4574-a14f-3e468f2ef16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 1\n",
    "num_workers = 0\n",
    "udb_train_set = MyDataset(data_dict, train_idxs, max_words_context, max_words_question, w2v_dim, w2v_undebiased)\n",
    "udb_test_set = MyDataset(data_dict, test_idxs, max_words_context, max_words_question, w2v_dim, w2v_undebiased)\n",
    "db_train_set = MyDataset(data_dict, train_idxs, max_words_context, max_words_question, w2v_dim, w2v_debiased)\n",
    "db_test_set = MyDataset(data_dict, test_idxs, max_words_context, max_words_question, w2v_dim, w2v_debiased)\n",
    "udb_train_loader = DataLoader(udb_train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "udb_test_loader = DataLoader(udb_test_set, batch_size=batch_size, num_workers=num_workers)\n",
    "db_train_loader = DataLoader(udb_train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "db_test_loader = DataLoader(udb_test_set, batch_size=batch_size, num_workers=num_workers)\n",
    "udb_result = train(isModeling, udb_train_loader, udb_test_loader, 'udb')\n",
    "db_result = train(isModeling, db_train_loader, db_test_loader, 'db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e64e4c-f924-4f11-a78c-80518986f883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "udb model\n",
      "prepare:3.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 1\n",
    "num_workers = 2\n",
    "udb_train_set = MyDataset(data_dict, train_idxs, max_words_context, max_words_question, w2v_dim, w2v_undebiased)\n",
    "udb_test_set = MyDataset(data_dict, test_idxs, max_words_context, max_words_question, w2v_dim, w2v_undebiased)\n",
    "db_train_set = MyDataset(data_dict, train_idxs, max_words_context, max_words_question, w2v_dim, w2v_debiased)\n",
    "db_test_set = MyDataset(data_dict, test_idxs, max_words_context, max_words_question, w2v_dim, w2v_debiased)\n",
    "udb_train_loader = DataLoader(udb_train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "udb_test_loader = DataLoader(udb_test_set, batch_size=batch_size, num_workers=num_workers)\n",
    "db_train_loader = DataLoader(udb_train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "db_test_loader = DataLoader(udb_test_set, batch_size=batch_size, num_workers=num_workers)\n",
    "udb_result = train(isModeling, udb_train_loader, udb_test_loader, 'udb')\n",
    "db_result = train(isModeling, db_train_loader, db_test_loader, 'db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cb2359d-afe5-4006-8d2b-215ff1354bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "context = torch.zeros(18896, 707, 300, dtype=float)\n",
    "question = torch.zeros(87599, 43, 30, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e853b76-0aec-42e0-b3df-0df2ae50f480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.991025775671"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "80521000800 / (1024*1024*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0299935e-f03d-4cf3-96a6-ae24366612dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18896"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('data/squad1.1/train-v1.1.json', encoding='utf-8') as f:\n",
    "    data_dict = json.load(f)\n",
    "count = 0\n",
    "for i, title in enumerate(data_dict['data']):\n",
    "    for j, paragraph in enumerate(title['paragraphs']):\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2df7a93-5793-42bf-b090-46ea22329983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from nltk.tokenize import word_tokenize\n",
    "with open('data/squad1.1/train-v1.1.json', encoding='utf-8') as f:\n",
    "    data_dict = json.load(f)\n",
    "max_words_context = 0\n",
    "max_words_question = 0\n",
    "for i, title in enumerate(data_dict['data']):\n",
    "    for j, paragraph in enumerate(title['paragraphs']):\n",
    "        context = word_tokenize(paragraph['context'].lower())\n",
    "        context = [word for word in context if word not in [',', '.']]\n",
    "        num_words_context = len(context)\n",
    "        if num_words_context > max_words_context:\n",
    "            max_words_context = num_words_context\n",
    "        for k, qa in enumerate(paragraph['qas']):\n",
    "            question = word_tokenize(qa['question'].lower())\n",
    "            question = [word for word in question if word not in [',', '.']]\n",
    "            num_words_question = len(question)\n",
    "            if num_words_question > max_words_question:\n",
    "                max_words_question = num_words_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfc35050-26bf-4096-984e-b4ecb4afad02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "707 43\n"
     ]
    }
   ],
   "source": [
    "print(max_words_context, max_words_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4620de7-5b27-410c-b816-fdd6513cc6ca",
   "metadata": {},
   "source": [
    "# データの準備, モデルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26baf1f4-c0db-4f8e-88d2-422d513516ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gensim\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17c584a9-c0a2-4a6a-b28c-6263e82f8d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'undebiased'\n",
    "w2v_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fe255ff-f49e-45ad-ba7c-0f58413115d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/squad1.1/train-v1.1.json', encoding='utf-8') as f:\n",
    "    data_dict = json.load(f)\n",
    "if task == 'undebiased':\n",
    "    w2v_model = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "        './data/GoogleNews-vectors-negative300.bin', binary=True\n",
    "    )\n",
    "elif task == 'debiased':\n",
    "    w2v_model = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "        './data/GoogleNews-vectors-negative300-hard-debiased.bin', binary=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "459d0e0e-2ac1-4931-a80e-ac03bc593d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_sentence = 0\n",
    "num_context = 0\n",
    "num_question = 0\n",
    "for title in data_dict['data']:\n",
    "    for paragraph in title['paragraphs']:\n",
    "        num_context += 1\n",
    "        num_sentence = len(sent_tokenize(paragraph['context']))\n",
    "        if num_sentence > max_num_sentence:\n",
    "            max_num_sentence = num_sentence\n",
    "        for qa in paragraph['qas']:\n",
    "            num_question += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef4e35d9-c1d0-4b7a-99ed-c9fbc996ceb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 18896 87599\n"
     ]
    }
   ],
   "source": [
    "print(max_num_sentence, num_context, num_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1b8ffd1e-facf-484c-9c89-e4a3c9348197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70079.2"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "87599*0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d727e340-1726-4845-a94a-57879eb1f73d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "questions = torch.zeros(num_question, 300)\n",
    "contexts = torch.zeros(num_context, max_num_sentence, 300)\n",
    "context_idxs = []\n",
    "answers = []\n",
    "context_id = 0\n",
    "question_id = 0\n",
    "for title in data_dict['data']:\n",
    "    for paragraph in title['paragraphs']:\n",
    "        sentences = sent_tokenize(paragraph['context'])\n",
    "        for i, sentence in enumerate(sentences):\n",
    "            words = [word for word in word_tokenize(sentence.lower()) if word in w2v_model.key_to_index]\n",
    "            if len(words) > 0:\n",
    "                contexts[context_id, i] += w2v_model[words].mean(axis=0)\n",
    "            else:\n",
    "                contexts[context_id, i] += torch.zeros(300)\n",
    "        context_id += 1\n",
    "        for qa in paragraph['qas']:\n",
    "            questions[question_id] += w2v_model[[word for word in word_tokenize(qa['question'].lower()) if word in w2v_model.key_to_index]].mean(axis=0)\n",
    "            question_id += 1\n",
    "            answer = qa['answers'][0]\n",
    "            context = paragraph['context']\n",
    "            context = context[:answer['answer_start']] + '_answer_tag_' + context[answer['answer_start']:]\n",
    "            sentences = sent_tokenize(context)\n",
    "            for sentence in sentences:\n",
    "                if '_answer_tag_' in sentence:\n",
    "                    answers.append(sentences.index(sentence))\n",
    "            context_idxs.append(context_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "085ca3ab-54da-4233-b070-746a82d97724",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = questions[:5]\n",
    "context = torch.stack([contexts[i] for i in context_idxs[:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d6f24827-3f3c-4be4-ab4c-ec05c4c47ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAModel2(nn.Module):\n",
    "    def __init__(self, w2v_dim, hid1, hid2, hid3, num_sentence):\n",
    "        super(QAModel2, self).__init__()\n",
    "        self.ln1 = nn.Linear(w2v_dim*2, hid1)\n",
    "        self.ln2 = nn.Linear(hid1, hid2)\n",
    "        self.ln3 = nn.Linear(hid2, hid3)\n",
    "        self.ln4 = nn.Linear(hid3, 1)\n",
    "        self.num_sentence = num_sentence\n",
    "    \n",
    "    def forward(self, q, s, batch_size):\n",
    "        print(q.shape, s.shape)\n",
    "        q = torch.stack([q for _ in range(self.num_sentence)], dim=1)\n",
    "        print(q.shape, s.shape)\n",
    "        x = torch.cat((q, s), dim=2)\n",
    "        print(x.shape)\n",
    "        x = self.ln1(x)\n",
    "        print(x.shape)\n",
    "        x = F.relu(x)\n",
    "        x = self.ln2(x)\n",
    "        print(x.shape)\n",
    "        x = F.relu(x)\n",
    "        x = self.ln3(x)\n",
    "        print(x.shape)\n",
    "        x = F.relu(x)\n",
    "        x = self.ln4(x)\n",
    "        print(x.shape)\n",
    "        x = x.view(batch_size, -1)\n",
    "        print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b30b14aa-3d2b-4eaf-9bfa-e1aaa896e5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 300]) torch.Size([5, 27, 300])\n",
      "torch.Size([5, 27, 300]) torch.Size([5, 27, 300])\n",
      "torch.Size([5, 27, 600])\n",
      "torch.Size([5, 27, 300])\n",
      "torch.Size([5, 27, 100])\n",
      "torch.Size([5, 27, 10])\n",
      "torch.Size([5, 27, 1])\n",
      "torch.Size([5, 27])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2680, -0.2677, -0.2679, -0.2679, -0.2662, -0.2680, -0.2680, -0.2681,\n",
       "         -0.2683, -0.2685, -0.2683, -0.2683, -0.2683, -0.2683, -0.2683, -0.2683,\n",
       "         -0.2683, -0.2683, -0.2683, -0.2683, -0.2683, -0.2683, -0.2683, -0.2683,\n",
       "         -0.2683, -0.2683, -0.2683],\n",
       "        [-0.2674, -0.2667, -0.2672, -0.2672, -0.2652, -0.2674, -0.2673, -0.2675,\n",
       "         -0.2676, -0.2678, -0.2678, -0.2673, -0.2673, -0.2673, -0.2673, -0.2673,\n",
       "         -0.2673, -0.2673, -0.2673, -0.2673, -0.2673, -0.2673, -0.2673, -0.2673,\n",
       "         -0.2673, -0.2673, -0.2673],\n",
       "        [-0.2667, -0.2657, -0.2661, -0.2666, -0.2639, -0.2665, -0.2663, -0.2666,\n",
       "         -0.2669, -0.2671, -0.2668, -0.2665, -0.2665, -0.2665, -0.2665, -0.2665,\n",
       "         -0.2665, -0.2665, -0.2665, -0.2665, -0.2665, -0.2665, -0.2665, -0.2665,\n",
       "         -0.2665, -0.2665, -0.2665],\n",
       "        [-0.2666, -0.2658, -0.2663, -0.2666, -0.2646, -0.2670, -0.2664, -0.2666,\n",
       "         -0.2670, -0.2670, -0.2672, -0.2664, -0.2664, -0.2664, -0.2664, -0.2664,\n",
       "         -0.2664, -0.2664, -0.2664, -0.2664, -0.2664, -0.2664, -0.2664, -0.2664,\n",
       "         -0.2664, -0.2664, -0.2664],\n",
       "        [-0.2670, -0.2662, -0.2670, -0.2670, -0.2649, -0.2673, -0.2670, -0.2673,\n",
       "         -0.2676, -0.2676, -0.2677, -0.2668, -0.2668, -0.2668, -0.2668, -0.2668,\n",
       "         -0.2668, -0.2668, -0.2668, -0.2668, -0.2668, -0.2668, -0.2668, -0.2668,\n",
       "         -0.2668, -0.2668, -0.2668]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = QAModel2(300, 300, 100, 10, max_num_sentence)\n",
    "model(question, context, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9752a99-f926-469f-8ca7-1343a94e739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAModel1(nn.Module):\n",
    "    def __init__(self, w2v_dim, hid1, hid2, num_sentence, hid3):\n",
    "        super(QAModel1, self).__init__()\n",
    "        self.QEnc1 = nn.Linear(w2v_dim, hid1)\n",
    "        self.QEnc2 = nn.Linear(hid1, hid2)\n",
    "        self.SEnc1 = nn.Linear(w2v_dim, hid1)\n",
    "        self.SEnc2 = nn.Linear(hid1, hid2)\n",
    "        self.Classifier1 = nn.Linear(hid2*(1+num_sentence), hid3)\n",
    "        self.Classifier2 = nn.Linear(hid3, num_sentence)\n",
    "    \n",
    "    def forward(self, q, s, batch_size):\n",
    "        print(q.shape, s.shape)\n",
    "        q = self.QEnc1(q)\n",
    "        print(q.shape, s.shape)\n",
    "        q = F.relu(q)\n",
    "        q = self.QEnc2(q)\n",
    "        print(q.shape, s.shape)\n",
    "        s = self.SEnc1(s)\n",
    "        print(q.shape, s.shape)\n",
    "        s = F.relu(s)\n",
    "        s = self.SEnc2(s)\n",
    "        print(q.shape, s.shape)\n",
    "        x = torch.cat((q, s.view(batch_size, -1)), dim=1)\n",
    "        print(x.shape)\n",
    "        x = self.Classifier1(x)\n",
    "        print(x.shape)\n",
    "        x = F.relu(x)\n",
    "        x = self.Classifier2(x)\n",
    "        print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "174f06e1-6e4b-420d-b6ba-d3ecf2d9b1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 300]) torch.Size([5, 27, 300])\n",
      "torch.Size([5, 100]) torch.Size([5, 27, 300])\n",
      "torch.Size([5, 10]) torch.Size([5, 27, 300])\n",
      "torch.Size([5, 10]) torch.Size([5, 27, 100])\n",
      "torch.Size([5, 10]) torch.Size([5, 27, 10])\n",
      "torch.Size([5, 280])\n",
      "torch.Size([5, 100])\n",
      "torch.Size([5, 27])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0701,  0.0847,  0.0458, -0.0125,  0.1104,  0.0637,  0.0051,  0.0331,\n",
       "         -0.0656,  0.0537,  0.0745,  0.0616,  0.0126,  0.0492, -0.1082, -0.0651,\n",
       "          0.0232, -0.0216, -0.0901,  0.0786, -0.0518,  0.0276, -0.0202,  0.0520,\n",
       "          0.0231,  0.0904, -0.0598],\n",
       "        [-0.0705,  0.0853,  0.0458, -0.0125,  0.1107,  0.0636,  0.0055,  0.0326,\n",
       "         -0.0656,  0.0540,  0.0747,  0.0629,  0.0126,  0.0499, -0.1085, -0.0654,\n",
       "          0.0237, -0.0211, -0.0894,  0.0795, -0.0539,  0.0276, -0.0189,  0.0520,\n",
       "          0.0224,  0.0905, -0.0603],\n",
       "        [-0.0710,  0.0853,  0.0463, -0.0128,  0.1106,  0.0632,  0.0051,  0.0326,\n",
       "         -0.0659,  0.0538,  0.0750,  0.0631,  0.0126,  0.0495, -0.1082, -0.0655,\n",
       "          0.0232, -0.0210, -0.0895,  0.0792, -0.0527,  0.0281, -0.0195,  0.0521,\n",
       "          0.0225,  0.0904, -0.0604],\n",
       "        [-0.0710,  0.0853,  0.0462, -0.0126,  0.1109,  0.0631,  0.0052,  0.0326,\n",
       "         -0.0662,  0.0538,  0.0752,  0.0634,  0.0127,  0.0499, -0.1082, -0.0654,\n",
       "          0.0234, -0.0205, -0.0896,  0.0796, -0.0535,  0.0279, -0.0189,  0.0519,\n",
       "          0.0223,  0.0904, -0.0604],\n",
       "        [-0.0704,  0.0854,  0.0460, -0.0128,  0.1106,  0.0634,  0.0056,  0.0324,\n",
       "         -0.0657,  0.0541,  0.0748,  0.0631,  0.0126,  0.0498, -0.1082, -0.0654,\n",
       "          0.0238, -0.0209, -0.0894,  0.0795, -0.0540,  0.0279, -0.0187,  0.0520,\n",
       "          0.0223,  0.0907, -0.0606]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = QAModel1(300, 100, 10, max_num_sentence, 100)\n",
    "model(question, context, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14885e7b-65c6-4fe6-91c8-3fbdd5d9681e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = ['this', 'is', 'a', 'pen', '.']\n",
    "w2v_model[[word for word in lst if word in w2v_model.key_to_index]].mean(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c16c8cfe-425c-45e1-9f36-66c9698ae920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = ['aaa', 'bbb', 'ccc']\n",
    "lst.index('aaa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fdf6e5c7-a4cd-441e-af1d-0009e31d09a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0064, -0.6183, -0.1550,  0.4980],\n",
       "        [-0.5288,  0.6372,  0.0337, -0.1819],\n",
       "        [ 0.6930, -0.7820, -0.1539,  0.7243]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = torch.randn(3,5)\n",
    "ln = torch.nn.Linear(5,4)\n",
    "ln(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f67249cb-d91f-46f9-9214-e4f12f45d2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0498,  0.2941, -0.0307,  0.3501], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = torch.randn(5)\n",
    "ln = torch.nn.Linear(5,4)\n",
    "ln(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "146bb0e3-9f09-4a45-ab53-09941dd9aa0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8205, -2.3091],\n",
      "        [-1.6800, -4.5780]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.8205],\n",
      "        [-2.3091],\n",
      "        [-1.6800],\n",
      "        [-4.5780]], grad_fn=<ViewBackward>)\n",
      "tensor([-0.8205, -2.3091, -1.6800, -4.5780,  7.0000,  8.0000,  9.0000],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "tmp = torch.tensor([[1.,2.,3.],[4.,5.,6.]])\n",
    "tmp_ = torch.tensor([7.,8.,9.])\n",
    "ln = torch.nn.Linear(3,2)\n",
    "print(ln(tmp))\n",
    "print(ln(tmp).view(-1, 1))\n",
    "print(torch.cat((ln(tmp).view(-1), tmp_), dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5a5b072c-b676-4f74-a4bb-8779024177cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.4548,  0.4365,  1.5742, -0.4050],\n",
      "         [-0.2412, -1.0823, -0.5030, -0.1549],\n",
      "         [-0.2878, -0.3213, -0.2747, -0.3449]],\n",
      "\n",
      "        [[ 0.4737,  0.2805,  0.3462,  0.5088],\n",
      "         [-0.8210,  1.9877,  0.3140,  2.5739],\n",
      "         [-0.2093, -0.8281, -0.2384, -0.9966]]])\n",
      "tensor([[-0.4548,  0.4365,  1.5742, -0.4050, -0.2412, -1.0823, -0.5030, -0.1549,\n",
      "         -0.2878, -0.3213, -0.2747, -0.3449],\n",
      "        [ 0.4737,  0.2805,  0.3462,  0.5088, -0.8210,  1.9877,  0.3140,  2.5739,\n",
      "         -0.2093, -0.8281, -0.2384, -0.9966]])\n"
     ]
    }
   ],
   "source": [
    "tmp = torch.randn(2,3,4)\n",
    "print(tmp)\n",
    "print(tmp.reshape(2, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "57492320-0e2d-4f41-b276-c07bd78fffea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3788,  1.4626, -1.4232,  0.7177,  0.8226,  1.7125],\n",
       "        [ 0.2577,  0.3597, -0.5616,  0.0729,  0.4379, -1.1221]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp1 = torch.randn(2,3)\n",
    "tmp2 = torch.randn(2,3)\n",
    "torch.cat((tmp1, tmp2), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9517a7a6-bba9-4b18-8d6c-6dbce34fe120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0267,  1.0830,  1.6508, -0.2290, -0.2771],\n",
       "         [ 1.0267,  1.0830,  1.6508, -0.2290, -0.2771],\n",
       "         [ 1.0267,  1.0830,  1.6508, -0.2290, -0.2771],\n",
       "         [ 1.0267,  1.0830,  1.6508, -0.2290, -0.2771]],\n",
       "\n",
       "        [[-0.1283, -0.0267, -0.1863,  0.6343, -0.4826],\n",
       "         [-0.1283, -0.0267, -0.1863,  0.6343, -0.4826],\n",
       "         [-0.1283, -0.0267, -0.1863,  0.6343, -0.4826],\n",
       "         [-0.1283, -0.0267, -0.1863,  0.6343, -0.4826]],\n",
       "\n",
       "        [[ 0.3379,  0.2892,  0.7654, -0.0264, -1.0259],\n",
       "         [ 0.3379,  0.2892,  0.7654, -0.0264, -1.0259],\n",
       "         [ 0.3379,  0.2892,  0.7654, -0.0264, -1.0259],\n",
       "         [ 0.3379,  0.2892,  0.7654, -0.0264, -1.0259]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = torch.randn(3,5)\n",
    "tmp = torch.stack([tmp for i in range(4)], dim=1)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c3bb2644-73b4-44ed-b7be-3a0f53a66ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1476,  0.8880,  0.4228, -1.4989, -0.6753],\n",
       "         [-1.9026, -0.1777,  1.5500,  1.3007,  0.6102],\n",
       "         [ 1.8626, -0.3656,  0.7621,  1.8038, -0.9714],\n",
       "         [-0.2793, -0.0034,  0.2644, -0.9639, -0.6296]],\n",
       "\n",
       "        [[-1.5686,  0.7946, -0.1522,  0.4611,  2.0914],\n",
       "         [ 0.6665,  0.0947, -0.2189,  0.1624,  1.6970],\n",
       "         [ 0.0466, -0.2103,  0.2228,  0.4168,  0.6527],\n",
       "         [ 0.2106, -0.1313,  0.7137, -0.3999, -1.2237]],\n",
       "\n",
       "        [[-1.0784,  0.6409, -0.4571,  0.7020,  1.0462],\n",
       "         [ 0.3668, -0.1541,  1.1270,  0.7282,  0.0456],\n",
       "         [ 2.7532,  0.1541,  0.5247,  1.1851, -0.8798],\n",
       "         [ 0.5988, -1.5035, -3.3389,  0.4964,  0.5917]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_ = torch.randn(3,4,5)\n",
    "tmp_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "281fb101-cc1a-4379-854d-fba808157411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0267,  1.0830,  1.6508, -0.2290, -0.2771,  1.1476,  0.8880,\n",
       "           0.4228, -1.4989, -0.6753],\n",
       "         [ 1.0267,  1.0830,  1.6508, -0.2290, -0.2771, -1.9026, -0.1777,\n",
       "           1.5500,  1.3007,  0.6102],\n",
       "         [ 1.0267,  1.0830,  1.6508, -0.2290, -0.2771,  1.8626, -0.3656,\n",
       "           0.7621,  1.8038, -0.9714],\n",
       "         [ 1.0267,  1.0830,  1.6508, -0.2290, -0.2771, -0.2793, -0.0034,\n",
       "           0.2644, -0.9639, -0.6296]],\n",
       "\n",
       "        [[-0.1283, -0.0267, -0.1863,  0.6343, -0.4826, -1.5686,  0.7946,\n",
       "          -0.1522,  0.4611,  2.0914],\n",
       "         [-0.1283, -0.0267, -0.1863,  0.6343, -0.4826,  0.6665,  0.0947,\n",
       "          -0.2189,  0.1624,  1.6970],\n",
       "         [-0.1283, -0.0267, -0.1863,  0.6343, -0.4826,  0.0466, -0.2103,\n",
       "           0.2228,  0.4168,  0.6527],\n",
       "         [-0.1283, -0.0267, -0.1863,  0.6343, -0.4826,  0.2106, -0.1313,\n",
       "           0.7137, -0.3999, -1.2237]],\n",
       "\n",
       "        [[ 0.3379,  0.2892,  0.7654, -0.0264, -1.0259, -1.0784,  0.6409,\n",
       "          -0.4571,  0.7020,  1.0462],\n",
       "         [ 0.3379,  0.2892,  0.7654, -0.0264, -1.0259,  0.3668, -0.1541,\n",
       "           1.1270,  0.7282,  0.0456],\n",
       "         [ 0.3379,  0.2892,  0.7654, -0.0264, -1.0259,  2.7532,  0.1541,\n",
       "           0.5247,  1.1851, -0.8798],\n",
       "         [ 0.3379,  0.2892,  0.7654, -0.0264, -1.0259,  0.5988, -1.5035,\n",
       "          -3.3389,  0.4964,  0.5917]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((tmp, tmp_), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "692ff1a8-95f7-4e9c-b75a-817633808136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "task = 'undebiased'\n",
    "df = pd.read_csv('outputs/QA_label_index_{}.csv'.format(task))\n",
    "answers = list(df['answers'])\n",
    "context_idxs = list(df['context_idxs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb10b17-8f46-4102-8612-0b91af7a1812",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
